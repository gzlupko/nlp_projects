---
title: "CDC_Study_New_Plots"
author: "Gian Zlupko"
date: '2022-06-27'
output: html_document
---

```{r setup, include=FALSE}
library(tidytext) 
library(tidyverse)
library(topicmodels) 
library(ldatuning)
library(textstem) 
library(SnowballC) 
library(tm)
library(car) 
library(stm) 
library(wesanderson)
#require("knitr")
#opts_knit$set(root.dir = "/Users/gianzlupko/Desktop/Workgroup/dnl_nlp/Studies/CDC_2021/data") 
```




```{r Data-Cleaning}
# load raw data and begin conversion to long data format 
# this row for reasons only data (no state or vax covariates)
#dat <- read_csv("cdc_raw_reasons.csv")
# this row for covariates included in broader data set: state and vax
setwd("/Users/gianzlupko/Desktop/Workgroup/dnl_nlp/Studies/CDC_2021/data")
dat <- read_csv("cdc_full_data.csv")
# rename columns
dat <- dat %>%
   rename(Decision = Q4, Reason1 = Q12_1, Reason2 = Q12_2, Reason3 = Q12_3, 
          Reason4 = Q12_4, Reason5 = Q12_5, Reason6 = Q12_6, Reason7 = Q12_7, 
          Reason8 = Q12_8, Reason9 = Q12_9, Reason10 = Q12_10)  
# rename additional columns to shorter headers 
dat <- dat %>%
  rename(MacroReasoning = MacroReasoning_3_items_standardized_Ave)
# first add unique participant id 
dat1 <- dat %>%
  mutate(participant_id = 1:length(Decision))
# use duplicated() to check that each participant_id is unique 
duplicated(dat1[ ,c("participant_id")])
# after confirming that all ids are unique
# create one data set of reasons that will be 
# used to convert from wide to long format 
dat2 <- dat1 %>%
  select(participant_id, Reason1, Reason2, Reason3, Reason3, 
         Reason4, Reason5, Reason6, Reason7, Reason8, Reason9, Reason10)  
# first convert reasons to long data format
data_long <- dat2 %>%
  gather(key = "Reason", 
         value = "Reason_Stated", c(-participant_id)) 
# next create a subset of the original data without the reasons data
# instead, retain only the BRT and decision variable scores to reattach
# to the long data frame
scores_to_merge <- dat1 %>%
  select(participant_id, ConfRfor, ConfRag, Att_Ave, SN_Ave, PC_Ave, MacroReasoning, 
         SN_general_Ave, SN_work_Ave, ProReas, ConReas, State)
# now, merge with the long formatted reasons data and merge by participant_id
reasons_formatted <- merge(x = data_long, 
                           y = scores_to_merge, 
                           by = "participant_id", 
                           all.y = T)
# finally remove rows with NA values 
reasons_long <- reasons_formatted %>%
  filter(!is.na(Reason_Stated)) 
# add row_id, which will be used after creating topic model
# to re-assign the topic model output back to the unique row id 
reasons_long$row_id <- paste(1:nrow(reasons_long))
```



Structural Topic Modeling Framework
Resources: 
1. Roberts et al (2018) - STM: R Package for Structural Topic Models: 
https://cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf

2. University of Oregon: 
https://blogs.uoregon.edu/rclub/2016/04/05/structural-topic-modeling/

```{r}
reasons_long <- reasons_long %>%
  rename(document = Reason_Stated) 
# test remove NA from ConfRfor
#reasons_long <- reasons_long %>%
  #filter(!is.na(ConfRfor)) 
# uses textProcessor() function from tm package 
processed <- textProcessor(reasons_long$document, metadata = reasons_long)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
# run an initial 4-topic fit to explore initial elements in the corpus 
fit0 <- stm(out$documents, # the documents
            out$vocab, # the words
            K = 4, # 10 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral")  
# look at top words
labelTopics(fit0)
plot.STM(fit0, type = "summary") 
# correlations between topics 
round(topicCorr(fit0)$cor, 2) # just the correlations between topics
```

Model Diagnostics: examining semantic coherence and exclusivity 

```{r, include F}
# identify best k out of 10 topics 
ntopics <- searchK(out$documents, out$vocab, K = c(2, 3 , 4, 5, 6, 7, 8, 9, 10), data = meta)
# fit statistics for k = c(2:10) estimations  
plot(ntopics) 
# selectModel() approach can also be used in addition to searchK() 
# whereby models are selected that optimize on exclusivity and semantic coherence 
stm_select_mod <- selectModel(out$documents, out$vocab, K = 15, 
                              prevalence = ~State, max.em.its = 75, data = out$meta, 
                              runs = 15) 
plotModels(stm_select_mod, pch = c(1,2,3,4), legend.position = "bottomright")
```


Reasons For data - Topic Model Comparisons

The following code chunks compare 2, 3, and 4-topic model solutions to select the best one. First, a 2-topic model solution is generated along with corresponding figures, tables, and estimated effect analyses. 
```{r stm-2-topic}
fit_reasons_for_k2 <- stm(out$documents, # the documents
            out$vocab, # covariates expected to affect topic content 
            prevalence =~ participant_id + State,
            K = 2, # 2 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral") 
sageLabels(fit_reasons_for_k2) # only works with content covariates in the model
plot(fit_reasons_for_k2)
# correlations between topics 
round(topicCorr(fit_reasons_for_k2)$cor, 2) # just the correlations between topics
```


Reasons for K = 3, 4 and 5 


```{r}

model_fit_k3 <- stm(out$documents, # the documents
            out$vocab, # covariates expected to affect topic content 
            prevalence =~ participant_id + State,
            K = 3, # 2 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, 
            init.type = "Spectral") 

model_fit_k4 <- stm(out$documents, # the documents
            out$vocab, # covariates expected to affect topic content 
            prevalence =~ participant_id + State,
            K = 4, # 2 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, 
            init.type = "Spectral") 

model_fit_k5 <- stm(out$documents, # the documents
            out$vocab, # covariates expected to affect topic content 
            prevalence =~ participant_id + State,
            K = 5, # 2 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, 
            init.type = "Spectral") 

# save the .Rdata file to use stm objects with the stminsights package 
setwd("/Users/gianzlupko/Desktop/Workgroup/dnl_nlp/Studies/CDC_2021/data") 
save.image(file="cdc_study_stminsights.Rdata")  


```




Bar chart for 2-topic model solution fit 

```{r}
# Turn the STM object into a data frame. This is necessary so that we can work with it.
td_beta <- tidy(fit_two)
# create re-useable function for subsequent topic model solutions 
# bar chart uses wesanderson color palettes
word_probs <- function(td_beta) { 
  
  td_beta %>%
  # Group by topic
  group_by(topic) %>%
  # Take the top 10 based on beta
  top_n(10, beta) %>%
  # Ungroup
  ungroup() %>%
  # Generate the variables topic and term
  dplyr::mutate(topic = paste0("Topic ", topic),
                term = reorder_within(term, beta, topic)) %>%
  # And plot it
  ggplot() +
  # Using a bar plot with the terms on the x-axis, the beta on the y-axis, filled by topic
  geom_col(aes(x = term, y = beta, fill = as.factor(topic)),
           alpha = 0.8,
           show.legend = FALSE) +
  # Do a facet_wrap by topic
  facet_wrap(~ topic, scales = "free_y") +
  # And flip the plot
  coord_flip() +
  scale_x_reordered() +
  # Label the x-axis, y-axis, as well as title
  labs(
    y = expression(beta),
    title = "Highest word probabilities for each topic") +
  # And finally define the colors
  scale_fill_manual(values = wes_palette("Darjeeling1"))
  
  
  }
# generate bar chart for 2 topic solution
word_probs(td_beta) 
```


```{r}
# look at highest word probability
labelTopics(fit_two)
plot.STM(fit_two, type = "labels") 
plot.STM(fit_two, type = "summary", main = "2-Topic Expected Proportions") 
# look at 
plot.STM(fit_two, type = "labels", labeltype = c("frex"), main = "2-Topic Solution: Exclusivity")  
# outputs most representative documents for a particular topic
findThoughts(
  # Your topic model
  fit_two,
  texts = reasons_long, 
  n = 3, 
  topics = c(1,2,3)
)
```


Use model outputs to assign categorical variables for regression 

```{r}
# Attitude 
est_two_1 <- estimateEffect(1:2 ~ Att_Ave, stmobj = fit_two, metadata = out$meta, 
                       uncertainty = "None")   
summary(est_two_1) 
# Subjective Norm 
est_two_2 <- estimateEffect(1:2 ~ SN_Ave, stmobj = fit_two, metadata = out$meta, 
                       uncertainty = "None")   
summary(est_two_2)
# Perceived Control
est_two_3 <- estimateEffect(1:2 ~ PC_Ave, stmobj = fit_two, metadata = out$meta, 
                       uncertainty = "None")   
summary(est_two_3)
plot(est_two_1, covariate = "Att_Ave", topics = c(1,2), 
     model = fit_two, 
     method = "continuous") 
# show the estimated relationship between Topic 1 and Attitude 
plot(est_two_1, covariate = "Att_Ave", model = fit_two,
     method = "continuous", xlab = "Attitude", topics = c(1))
```


Generate a 3-topic solution with figures and diagnostics. 

```{r stm-3-topic}
fit_three <- stm(out$documents, # the documents
            out$vocab, # covariates expected to affect topic content 
            prevalence =~ participant_id + State,
            K = 3, # 2 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral") 
sageLabels(fit_three) # only works with content covariates in the model
plot(fit_three)
# correlations between topics 
round(topicCorr(fit_three)$cor, 2) #correlations between topics
# highest word probabilities bar chart 
td_beta <- tidy(fit_three) 
word_probs(td_beta)
# look at highest word probability
labelTopics(fit_three)
# top terms conditioning on exclusivity of terms by between topics 
plot.STM(fit_three, type = "labels", labeltype = c("frex"), main = "3-Topic Solution: Exclusivity")  
# perpsective plot 
plot.STM(fit_three, type = "perspectives", topics = c(2,3))   
# expected proportion of topics in all reasons for data 
plot.STM(fit_three, type = "summary", main = "3-Topic Expected Proportions") 
# custom approach to summarizing topic proportions 
reasons_for_proportions <- make.dt(fit_three) 
summarize_all(reasons_for_proportions, mean)
```


Calculate estimated effects for the 3-topic solution

```{r stm-3-topic-estimates}
# Attitude 
est_three_1 <- estimateEffect(1:3 ~ Att_Ave, stmobj = fit_three, metadata = out$meta, 
                              uncertainty = "None")    
summary(est_three_1) 
# Subjective Norm 
est_three_2 <- estimateEffect(1:3 ~ SN_Ave, stmobj = fit_three, metadata = out$meta, 
                       uncertainty = "None")   
summary(est_three_2)
# Perceived Control
est_three_3 <- estimateEffect(1:3 ~ PC_Ave, stmobj = fit_three, metadata = out$meta, 
                       uncertainty = "None")   
summary(est_three_3)
plot(est_two_1, covariate = "Att_Ave", topics = c(1,2), 
     model = fit_two, 
     method = "continuous") 
# show the estimated relationship between Topic 3 and PC 
plot(est_three_3, covariate = "PC_Ave", model = fit_three,
     method = "continuous", xlab = "Perceived Control", topics = c(3))
```


Generate a 4-topic model solution for comparison


```{r stm-4-topic-model}
fit_four <- stm(out$documents, # the documents
            out$vocab, # covariates expected to affect topic content 
            prevalence =~ participant_id + State,
            K = 4, # 2 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral") 
sageLabels(fit_four) # only works with content covariates in the model
plot(fit_four)
# correlations between topics 
round(topicCorr(fit_four)$cor, 2) # shows that correlations
# highest word probabilities bar chart 
td_beta <- tidy(fit_four) 
word_probs(td_beta)
# look at highest word probability
labelTopics(fit_four)
# top terms conditioning on exclusivity of terms by between topics 
plot.STM(fit_four, type = "labels", labeltype = c("frex"), main = "4-Topic Solution: Exclusivity")  
# perpsective plot: can add additional context on differentiation b/w two specific topics in the solution
plot.STM(fit_four, type = "perspectives", topics = c(3,4))   
# expected proportion of topics in all reasons for data 
plot.STM(fit_four, type = "summary", main = "4-Topic Expected Proportion")  
```



Calculate estimated effects for 4-topic solution 

```{r stm-4-topic-estimates}
# Attitude 
est_four_1 <- estimateEffect(1:4 ~ Att_Ave, stmobj = fit_four, metadata = out$meta, 
                             uncertainty = "None")   
summary(est_four_1) 
# Subjective Norm 
est_four_2 <- estimateEffect(1:4 ~ SN_Ave, stmobj = fit_four, metadata = out$meta, 
                       uncertainty = "None")   
summary(est_four_2)
# Perceived Control
est_four_3 <- estimateEffect(1:4 ~ PC_Ave, stmobj = fit_four, metadata = out$meta, 
                       uncertainty = "None")   
summary(est_four_3)
```




```{r stm-fit-statistics}
set.seed(6110) 
# use searchK() function to calculate fit statistics for 2, 3, and 4 topic solutions 
ntopics <- searchK(out$documents, out$vocab, K = c(2, 3, 4), data = meta)
# grab fit statistic values with the results df 
ntopics$results
# plot ntopics for fit statistic plots 
plot(ntopics) 
```





Reasons Against Data

Reasons Against data - Topic Model Comparisons

The following code chunks compare 2, 3, and 4-topic model solutions to select the best model for the reasons against data. First, a 2-topic model solution is generated along with corresponding figures, tables, and estimated effect analyses. 


```{r Against-Data-Cleaning}
# rename columns
against <- dat %>%
   rename(Against1 = Q33_1, Against2 = Q33_2, Against3 = Q33_3, 
          Against4 = Q33_4, Against5 = Q33_5, Against6 = Q33_6, Against7 = Q33_7, 
          Against8 = Q33_8, Against9 = Q33_9, Against10 = Q33_10)  
# first add unique participant id 
against1 <- against %>%
  mutate(participant_id = 1:length(Decision))
# use duplicated() to check that each participant_id is unique 
duplicated(against1[ ,c("participant_id")])
# after confirming that all ids are unique
# create one data set of reasons that will be 
# used to convert from wide to long format 
against_df <- against1 %>%
  select(participant_id, Against1, Against2, Against3, Against4, 
         Against5, Against6, Against7, Against8, Against9, Against10)  
# first convert reasons to long data format
against_long <- against_df %>%
  gather(key = "Against", 
         value = "Against_Stated", c(-participant_id)) 
# next create a subset of the original data without the reasons data
# instead, retain only the BRT and decision variable scores to reattach
# to the long data frame
against_to_merge <- against1 %>%
  select(participant_id, ConfRfor, ConfRag, Att_Ave, SN_Ave, PC_Ave, MacroReasoning, 
         SN_general_Ave, SN_work_Ave, ProReas, ConReas, State)
# now, merge with the long formatted reasons data and merge by participant_id
against_formatted <- merge(x = against_long, 
                           y = against_to_merge, 
                           by = "participant_id", 
                           all.y = T)
# finally remove rows with NA values 
against_long <- against_formatted %>%
  filter(!is.na(Against_Stated)) 
# add row_id, which will be used after creating topic model
# to re-assign the topic model output back to the unique row id 
against_long$row_id <- paste(1:nrow(against_long))
```


STM processing and model diagnostics 
```{r}
# renmae Against_Stated to 'document' for tm processing 
against_long <- against_long %>%
  rename(document = Against_Stated) 
# uses textProcessor() function from tm package 
against_processed <- textProcessor(against_long$document, metadata = against_long)
against_out <- prepDocuments(against_processed$documents, 
                             against_processed$vocab, 
                             against_processed$meta)
# two methods for identifying model fit 
# identify best k = c(2:10)
against_ntopics <- searchK(against_out$documents, against_out$vocab, K = c(2, 3, 4, 5, 6, 7, 8, 9, 10), data = meta)
plot(against_ntopics)
# show comparison of fit statistics for k = c(2:4)
against_ntopics <- searchK(against_out$documents, against_out$vocab, K = c(2, 3, 4), data = meta)
# plot fit statistic values for solutions on reasons against data 
plot(against_ntopics)
# grab fit statistics for topic model solutions on reasons against data 
against_ntopics$results
```


2-topic model solution for reasons against data 

```{r against-2-topic-solution}
against_fit_two <- stm(against_out$documents, # the documents
            against_out$vocab, # the words
            K = 2, # 3 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = against_out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral")  
# highest word probabilities bar chart 
td_beta <- tidy(against_fit_two) 
word_probs(td_beta)
# look at highest word probability
labelTopics(against_fit_two)
# top terms conditioning on exclusivity of terms by between topics 
plot.STM(against_fit_two, type = "labels", labeltype = c("frex"), main = "2-Topic Solution: Exclusivity")  
# perpsective plot: can add additional context on differentiation b/w two specific topics in the solution
plot.STM(against_fit_two, type = "perspectives", topics = c(1,2))   
# expected proportion of topics in all reasons for data 
plot.STM(against_fit_two, type = "summary", main = "2-Topic Expected Proportion")  
# look at top words by category
labelTopics(against_fit_two)
```



2-topic solution, Reasons Against - Estimated Effects 
```{r}
# Attitude 
against_est_two_1 <- estimateEffect(1:2 ~ Att_Ave, stmobj = against_fit_two, metadata = against_out$meta, 
                                    uncertainty = "None")    
summary(against_est_two_1) 
# Subjective Norm 
against_est_two_2 <- estimateEffect(1:2 ~ SN_Ave, stmobj = against_fit_two, metadata = against_out$meta, 
                       uncertainty = "None")   
summary(against_est_two_2)
# Perceived Control
against_est_two_3 <- estimateEffect(1:2 ~ PC_Ave, stmobj = against_fit_two, metadata = against_out$meta, 
                       uncertainty = "None")   
summary(against_est_two_3)
```



3-topic model solution for reasons against data 

```{r}
against_fit_three <- stm(against_out$documents, # the documents
            against_out$vocab, # the words
            K = 3, # 3 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = against_out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral")  
# highest word probabilities bar chart 
td_beta <- tidy(against_fit_three) 
word_probs(td_beta)
# look at highest word probability
labelTopics(against_fit_three)
# top terms conditioning on exclusivity of terms by between topics 
plot.STM(against_fit_three, type = "labels", labeltype = c("frex"), main = "3-Topic Solution: Exclusivity")  
# perpsective plot: can add additional context on differentiation b/w two specific topics in the solution
plot.STM(against_fit_three, type = "perspectives", topics = c(1,2))   
# expected proportion of topics in all reasons for data 
plot.STM(against_fit_three, type = "summary", main = "3-Topic Expected Proportion")  
# look at top words by category
labelTopics(against_fit_three)
# custom proption of topic in overall corpus for 3-topic model 
reasons_against_prop <- make.dt(against_fit_three)
summarize_all(reasons_against_prop, mean) 
```


Reasons Against Estimated Effects 3-topic solution 

```{r}
# Attitude 
set.seed(1061) 
against_est_three_1 <- estimateEffect(1:3 ~ Att_Ave, stmobj = against_fit_three, metadata = against_out$meta, 
                                    uncertainty = "None")    
summary(against_est_three_1) 
# Subjective Norm 
against_est_three_2 <- estimateEffect(1:3 ~ SN_Ave, stmobj = against_fit_three, metadata = against_out$meta, 
                       uncertainty = "None")   
summary(against_est_three_2)
# Perceived Control
against_est_three_3 <- estimateEffect(1:3 ~ PC_Ave, stmobj = against_fit_three, metadata = against_out$meta, 
                       uncertainty = "None")   
summary(against_est_three_3)
# show the estimated relationship between Against Topic 3 and PC 
plot(against_est_three_1, covariate = "Att_Ave", model = against_fit_three,
     method = "continuous", xlab = "Attitude", topics = c(1, 2), 
     main = "Attitude by Topic 1 and Topic 2 \n in Reasons Against")  
```


4-topic model solution for reasons against data 


```{r stm-against-4-topic-model}
against_fit_four <- stm(against_out$documents, # the documents
            against_out$vocab, # the words
            K = 4, 
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = against_out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral")  
# highest word probabilities bar chart 
td_beta <- tidy(against_fit_four) 
word_probs(td_beta)
# look at highest word probability
labelTopics(against_fit_four)
# top terms conditioning on exclusivity of terms by between topics 
plot.STM(against_fit_four, type = "labels", labeltype = c("frex"), main = "4-Topic Solution: Exclusivity")  
# perpsective plot: can add additional context on differentiation b/w two specific topics in the solution
plot.STM(against_fit_four, type = "perspectives", topics = c(1,2))   
# expected proportion of topics in all reasons for data 
plot.STM(against_fit_four, type = "summary", main = "4-Topic Expected Proportion")  
# look at top words by category
labelTopics(against_fit_four)
```


Reasons Against Estimated Effects 3-topic solution 

```{r 4-topic-estimated-effects}
# Attitude 
set.seed(10826) 
against_est_four_1 <- estimateEffect(1:4 ~ Att_Ave, stmobj = against_fit_four, metadata = against_out$meta, 
                                    uncertainty = "None")    
summary(against_est_four_1) 
# Subjective Norm 
against_est_four_2 <- estimateEffect(1:4 ~ SN_Ave, stmobj = against_fit_four, metadata = against_out$meta, 
                       uncertainty = "None")   
summary(against_est_four_2)
# Perceived Control
against_est_four_3 <- estimateEffect(1:4 ~ PC_Ave, stmobj = against_fit_four, metadata = against_out$meta, 
                       uncertainty = "None")   
summary(against_est_four_3)
# show the estimated relationship between Against Topic 3 and PC 
plot(against_est_four_1, covariate = "Att_Ave", model = against_fit_four,
     method = "continuous", xlab = "Attitude", topics = c(3), 
     main = "Attitude by Topic 3 \n in Reasons Against")  















