{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Hugging Face \n",
        "\n",
        "ðŸ¤—\n",
        "\n",
        "First, install the transformers library in the Colab notebook. "
      ],
      "metadata": {
        "id": "gLdx19993dq8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tXsnaTgx3Zww"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers \n",
        "!pip install Xformers "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sentiment analysis\n",
        "Next, we can use a simple pipeline to perform sentiment analysis. "
      ],
      "metadata": {
        "id": "S9L2yqGd36pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# initialize the classifier \n",
        "classifier = pipeline(\"sentiment-analysis\") \n",
        "\n",
        "# apply the classifier to the following string\n",
        "res = classifier(\"I've been waiting for a Hugging Face course my whole life.\")\n",
        "\n",
        "# print results from sentiment analysis\n",
        "print(res) "
      ],
      "metadata": {
        "id": "o7NZybMQ4ACM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb135a54-bb47-44da-aa0c-3658138fb225"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9982948899269104}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice Python recognized that no model was supplied. To provide a specific model in a pipeline, use the following argument. "
      ],
      "metadata": {
        "id": "FOdYkZaQ-o9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(model = \"roberta-large-mnli\") \n",
        "\n",
        "# apply the model that was specified \n",
        "pipe(\"This restaurant is awesome\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K50KYp---oSE",
        "outputId": "51c66d6e-c02c-4c7e-df6e-31c0188fc5cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEUTRAL', 'score': 0.7313134670257568}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text generation"
      ],
      "metadata": {
        "id": "B7NeC5o276Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model = \"distilgpt2\") \n",
        "\n",
        "res = generator(\n",
        "    \"In this course, we will teach you how to work with data types like\", \n",
        "    max_length = 50, \n",
        "    num_return_sequences = 1,\n",
        ")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgStSkQ_7-TX",
        "outputId": "718b6236-b148-4ffa-8664-9c7cf38efa68"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'In this course, we will teach you how to work with data types like a spreadsheet.\\n\\n\\nIf you follow or follow the tutorial from this course, look for tutorials and videos on how you can get started with the same principles as ours.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Zero-Shot classification"
      ],
      "metadata": {
        "id": "c5-sLntU8qTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize \n",
        "classifier_zero = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "res = classifier_zero(\n",
        "    \"This is a course about Python list comprehension\",\n",
        "    candidate_labels = [\"education\", \"politics\", \"business\"]\n",
        ")\n",
        "print(res) \n",
        "\n",
        "res1 = classifier_zero(\n",
        "    \"the candidate was absent from the polling site\", \n",
        "    candidate_labels = [\"sports\", \"politics\", \"economics\"]\n",
        ")\n",
        "\n",
        "print(res1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxXrg3Ae9L9W",
        "outputId": "ad948568-35d4-46f0-b72b-8e84dc11127b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'This is a course about Python list comprehension', 'labels': ['education', 'business', 'politics'], 'scores': [0.9622024893760681, 0.026841476559638977, 0.010956035926938057]}\n",
            "{'sequence': 'the candidate was absent from the polling site', 'labels': ['politics', 'economics', 'sports'], 'scores': [0.9342160820960999, 0.04413432255387306, 0.021649545058608055]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenization"
      ],
      "metadata": {
        "id": "JV7d0tP49_SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "zdCatKWl_ld2",
        "outputId": "9f25a6b9-4c3f-4b65-8d5a-7da4725c54c4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6028b117c0bd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransfomers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transfomers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}